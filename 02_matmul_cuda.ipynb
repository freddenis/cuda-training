{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNVdoEx7tvPBrb0xu2UKzjX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# A quick check there is a CUDA device associated to this session (if not use Runtime => Change runtime type and choose GPU)\n","# Also checking that the CUDA env (nvcc) is correctly set up\n","!nvidia-smi\n","!nvcc --version"],"metadata":{"id":"KmyJ-4eHZXKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SrmbR8TWl_J"},"outputs":[],"source":["# A CUDA Matric Mutiplication source code\n","# You can change the size of the Matrix in the main()\n","#     constexpr int N = 1000;\n","#\n","%%writefile matrix_multiply.cu\n","\n","#include <iostream>\n","#include <vector>\n","#include <random>\n","\n","using namespace std;\n","\n","// CUDA kernel for matrix multiplication\n","__global__ void matrixMultiplyKernel(int *a, int *b, int *c, int N) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < N && col < N) {\n","        int sum = 0;\n","        for (int k = 0; k < N; ++k) {\n","            sum += a[row * N + k] * b[k * N + col];\n","        }\n","        c[row * N + col] = sum;\n","    }\n","}\n","\n","// Function to generate a random matrix of size N x N\n","void generateRandomMatrix(vector<int>& matrix, int N) {\n","    random_device rd;\n","    mt19937 gen(rd());\n","    uniform_int_distribution<int> dis(1, 100); // Random numbers between 1 and 100\n","\n","    matrix.resize(N * N);\n","    for (int i = 0; i < N * N; ++i) {\n","        matrix[i] = dis(gen);\n","    }\n","}\n","\n","// Function to display a portion of the matrix\n","void displayMatrix(const vector<int>& matrix, int N) {\n","    const int MAX_DISPLAY_SIZE = 10;\n","    for (int i = 0; i < min(MAX_DISPLAY_SIZE, N); ++i) {\n","        for (int j = 0; j < min(MAX_DISPLAY_SIZE, N); ++j) {\n","            cout << matrix[i * N + j] << \"\\t\";\n","        }\n","        if (N > MAX_DISPLAY_SIZE) cout << \"...\";\n","        cout << endl;\n","    }\n","}\n","\n","// Function to perform matrix multiplication on GPU\n","void matrixMultiplyCUDA(const vector<int>& A, const vector<int>& B, vector<int>& C, int N) {\n","    int *d_A, *d_B, *d_C;\n","\n","    // Allocate device memory\n","    cudaMalloc((void **)&d_A, N * N * sizeof(int));\n","    cudaMalloc((void **)&d_B, N * N * sizeof(int));\n","    cudaMalloc((void **)&d_C, N * N * sizeof(int));\n","\n","    // Copy input matrices from host to device\n","    cudaMemcpy(d_A, A.data(), N * N * sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, B.data(), N * N * sizeof(int), cudaMemcpyHostToDevice);\n","\n","    // Define grid and block dimensions\n","    dim3 blockDim(16, 16);\n","    dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n","\n","    // Launch kernel\n","    matrixMultiplyKernel<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);\n","\n","    // Copy result matrix from device to host\n","    cudaMemcpy(C.data(), d_C, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n","\n","    // Free device memory\n","    cudaFree(d_A);\n","    cudaFree(d_B);\n","    cudaFree(d_C);\n","}\n","\n","int main() {\n","    constexpr int N = 1000;\n","\n","    vector<int> A, B, C;\n","    generateRandomMatrix(A, N);\n","    generateRandomMatrix(B, N);\n","    C.resize(N * N);\n","\n","    cout << \"Matrix A:\" << endl;\n","    displayMatrix(A, N);\n","\n","    cout << \"\\nMatrix B:\" << endl;\n","    displayMatrix(B, N);\n","\n","    // Perform matrix multiplication on GPU\n","    matrixMultiplyCUDA(A, B, C, N);\n","\n","    cout << \"\\nResult of Matrix Multiplication:\" << endl;\n","    displayMatrix(C, N);\n","\n","    return 0;\n","}"]},{"cell_type":"code","source":["# Compile\n","!nvcc -o matrix_multiply matrix_multiply.cu"],"metadata":{"id":"e8iXzBPIYbin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the Matrix Multiplicationm it should take no time using CUDA vs when not using CUDA\n","!time ./matrix_multiply"],"metadata":{"id":"ztTkI0SxW4po"},"execution_count":null,"outputs":[]}]}