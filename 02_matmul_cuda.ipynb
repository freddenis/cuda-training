{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNVdoEx7tvPBrb0xu2UKzjX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# A quick check there is a CUDA device associated to this session (if not use Runtime => Change runtime type and choose GPU)\n","# Also checking that the CUDA env (nvcc) is correctly set up\n","!nvidia-smi\n","!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KmyJ-4eHZXKP","executionInfo":{"status":"ok","timestamp":1713950081313,"user_tz":-120,"elapsed":609,"user":{"displayName":"Fred DENIS","userId":"08603485953641292647"}},"outputId":"e06dd95b-1b1f-4010-89f7-7503991a7af1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Apr 24 09:14:42 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8SrmbR8TWl_J","executionInfo":{"status":"ok","timestamp":1713950084971,"user_tz":-120,"elapsed":226,"user":{"displayName":"Fred DENIS","userId":"08603485953641292647"}},"outputId":"3f222e88-ab71-4b0d-af0e-c54d87c6aa6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing matrix_multiply.cu\n"]}],"source":["# A CUDA Matric Mutiplication source code\n","# You can change the size of the Matrix in the main()\n","#     constexpr int N = 1000;\n","#\n","%%writefile matrix_multiply.cu\n","\n","#include <iostream>\n","#include <vector>\n","#include <random>\n","\n","using namespace std;\n","\n","// CUDA kernel for matrix multiplication\n","__global__ void matrixMultiplyKernel(int *a, int *b, int *c, int N) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < N && col < N) {\n","        int sum = 0;\n","        for (int k = 0; k < N; ++k) {\n","            sum += a[row * N + k] * b[k * N + col];\n","        }\n","        c[row * N + col] = sum;\n","    }\n","}\n","\n","// Function to generate a random matrix of size N x N\n","void generateRandomMatrix(vector<int>& matrix, int N) {\n","    random_device rd;\n","    mt19937 gen(rd());\n","    uniform_int_distribution<int> dis(1, 100); // Random numbers between 1 and 100\n","\n","    matrix.resize(N * N);\n","    for (int i = 0; i < N * N; ++i) {\n","        matrix[i] = dis(gen);\n","    }\n","}\n","\n","// Function to display a portion of the matrix\n","void displayMatrix(const vector<int>& matrix, int N) {\n","    const int MAX_DISPLAY_SIZE = 10;\n","    for (int i = 0; i < min(MAX_DISPLAY_SIZE, N); ++i) {\n","        for (int j = 0; j < min(MAX_DISPLAY_SIZE, N); ++j) {\n","            cout << matrix[i * N + j] << \"\\t\";\n","        }\n","        if (N > MAX_DISPLAY_SIZE) cout << \"...\";\n","        cout << endl;\n","    }\n","}\n","\n","// Function to perform matrix multiplication on GPU\n","void matrixMultiplyCUDA(const vector<int>& A, const vector<int>& B, vector<int>& C, int N) {\n","    int *d_A, *d_B, *d_C;\n","\n","    // Allocate device memory\n","    cudaMalloc((void **)&d_A, N * N * sizeof(int));\n","    cudaMalloc((void **)&d_B, N * N * sizeof(int));\n","    cudaMalloc((void **)&d_C, N * N * sizeof(int));\n","\n","    // Copy input matrices from host to device\n","    cudaMemcpy(d_A, A.data(), N * N * sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, B.data(), N * N * sizeof(int), cudaMemcpyHostToDevice);\n","\n","    // Define grid and block dimensions\n","    dim3 blockDim(16, 16);\n","    dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n","\n","    // Launch kernel\n","    matrixMultiplyKernel<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);\n","\n","    // Copy result matrix from device to host\n","    cudaMemcpy(C.data(), d_C, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n","\n","    // Free device memory\n","    cudaFree(d_A);\n","    cudaFree(d_B);\n","    cudaFree(d_C);\n","}\n","\n","int main() {\n","    constexpr int N = 1000;\n","\n","    vector<int> A, B, C;\n","    generateRandomMatrix(A, N);\n","    generateRandomMatrix(B, N);\n","    C.resize(N * N);\n","\n","    cout << \"Matrix A:\" << endl;\n","    displayMatrix(A, N);\n","\n","    cout << \"\\nMatrix B:\" << endl;\n","    displayMatrix(B, N);\n","\n","    // Perform matrix multiplication on GPU\n","    matrixMultiplyCUDA(A, B, C, N);\n","\n","    cout << \"\\nResult of Matrix Multiplication:\" << endl;\n","    displayMatrix(C, N);\n","\n","    return 0;\n","}"]},{"cell_type":"code","source":["# Compile\n","!nvcc -o matrix_multiply matrix_multiply.cu"],"metadata":{"id":"e8iXzBPIYbin","executionInfo":{"status":"ok","timestamp":1713950094020,"user_tz":-120,"elapsed":4629,"user":{"displayName":"Fred DENIS","userId":"08603485953641292647"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Run the Matrix Multiplicationm it should take no time using CUDA vs when not using CUDA\n","!time ./matrix_multiply"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztTkI0SxW4po","executionInfo":{"status":"ok","timestamp":1713950097306,"user_tz":-120,"elapsed":735,"user":{"displayName":"Fred DENIS","userId":"08603485953641292647"}},"outputId":"4a656adb-6d2b-4dc9-a7c6-2b3d8940c287"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix A:\n","63\t51\t95\t31\t7\t24\t17\t35\t35\t3\t...\n","71\t37\t5\t57\t44\t96\t97\t71\t71\t85\t...\n","88\t79\t96\t84\t83\t61\t95\t75\t2\t31\t...\n","87\t29\t57\t3\t39\t29\t20\t52\t92\t52\t...\n","16\t66\t69\t81\t61\t6\t75\t58\t27\t65\t...\n","12\t64\t65\t1\t16\t32\t30\t79\t48\t12\t...\n","74\t74\t91\t61\t51\t68\t52\t56\t50\t24\t...\n","75\t42\t62\t31\t17\t43\t54\t74\t95\t93\t...\n","67\t49\t7\t5\t17\t97\t3\t97\t46\t93\t...\n","13\t89\t49\t63\t75\t18\t47\t97\t98\t76\t...\n","\n","Matrix B:\n","45\t33\t22\t39\t9\t51\t47\t55\t85\t25\t...\n","8\t57\t59\t96\t98\t48\t26\t94\t79\t18\t...\n","10\t69\t3\t93\t40\t25\t29\t58\t66\t16\t...\n","93\t56\t23\t2\t73\t75\t66\t71\t18\t77\t...\n","80\t74\t85\t3\t79\t86\t9\t86\t90\t64\t...\n","61\t27\t100\t96\t43\t22\t1\t54\t94\t2\t...\n","31\t65\t85\t39\t51\t68\t76\t7\t98\t96\t...\n","46\t78\t38\t2\t14\t36\t57\t72\t11\t2\t...\n","75\t36\t18\t49\t77\t96\t60\t47\t39\t33\t...\n","91\t89\t5\t59\t96\t40\t45\t61\t83\t65\t...\n","\n","Result of Matrix Multiplication:\n","2514812\t2538732\t2497897\t2461036\t2574760\t2579635\t2502016\t2574394\t2527094\t2523245\t...\n","2561442\t2551079\t2532669\t2508844\t2635120\t2618876\t2599383\t2664020\t2610235\t2577856\t...\n","2516753\t2523094\t2492636\t2500269\t2578648\t2570720\t2529936\t2560041\t2531841\t2573958\t...\n","2458204\t2483105\t2407646\t2463575\t2543707\t2543021\t2499937\t2503444\t2481472\t2531716\t...\n","2529798\t2556777\t2445621\t2438452\t2561744\t2535768\t2469248\t2543616\t2523917\t2536051\t...\n","2599658\t2575153\t2491863\t2477324\t2639719\t2605642\t2558347\t2674823\t2593152\t2577358\t...\n","2542480\t2551871\t2481463\t2490824\t2611546\t2586538\t2515017\t2563282\t2552649\t2562233\t...\n","2551587\t2505384\t2532811\t2531337\t2601257\t2618884\t2527726\t2592337\t2512709\t2480506\t...\n","2595291\t2654687\t2553234\t2499072\t2655648\t2645725\t2547561\t2673546\t2578380\t2604832\t...\n","2567857\t2468767\t2497509\t2470536\t2570487\t2574184\t2496613\t2579007\t2467501\t2527602\t...\n","\n","real\t0m0.517s\n","user\t0m0.145s\n","sys\t0m0.232s\n"]}]}]}